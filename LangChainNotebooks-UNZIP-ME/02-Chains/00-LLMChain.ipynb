{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcded1a6-2430-4707-a78c-c82f4c5ee6fc",
   "metadata": {},
   "source": [
    "<a href = \"https://www.pieriantraining.com\"><img src=\"../PT Centered Purple.png\"> </a>\n",
    "\n",
    "<em style=\"text-align:center\">Copyrighted by Pierian Training</em>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728f1747-b8fc-4d31-96c2-047fc83c079d",
   "metadata": {},
   "source": [
    "#  Basic Single Chain\n",
    "\n",
    "Chains allow us to combine multiple components together to create a single, coherent application. For example, we can create a chain that takes user input, formats it with a PromptTemplate, and then passes the formatted response to an LLM. We can build more complex chains by combining multiple chains together, or by combining chains with other components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "244f42d8-2349-446e-a1c2-ae4b8d3ee38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "f = open('C:\\\\Users\\\\Marcial\\\\Desktop\\\\desktop_openai.txt')\n",
    "os.environ['OPENAI_API_KEY'] = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba9cdab6-7337-42ee-9299-9bd98b6105fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef4ce02d-d8aa-44f3-aa91-cfb8cfc06f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_message_prompt = HumanMessagePromptTemplate.from_template(\n",
    "        \"Make up a funny company name for a company that produces {product}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bda465bc-5863-4393-a67d-97352a32b1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt_template = ChatPromptTemplate.from_messages([human_message_prompt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8278652-4c42-4ef1-a32b-6e971cccf1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb223191-78c9-421e-a8a3-67e016b10faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "chain = LLMChain(llm=chat, prompt=chat_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d4b3baf-5a5e-40bd-b916-bf0460a762f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Byte Me Computers\n"
     ]
    }
   ],
   "source": [
    "print(chain.run(product=\"Computers\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bf340a-9054-4ede-a945-500250c4b7e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
