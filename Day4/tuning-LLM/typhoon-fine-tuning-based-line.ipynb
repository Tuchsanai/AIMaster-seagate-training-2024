{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0a390da7",
      "metadata": {
        "id": "0a390da7",
        "papermill": {
          "duration": 0.149952,
          "end_time": "2024-04-20T04:52:11.850095",
          "exception": false,
          "start_time": "2024-04-20T04:52:11.700143",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Hello! and welcome to my Typhoon fine tuning notebook.\n",
        "\n",
        "\n",
        "Hello! and welcome to my Typhoon fine tuning notebook.\n",
        "\n",
        "Learn more about the model: https://arxiv.org/abs/2312.13951"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "257fa2cb",
      "metadata": {
        "id": "257fa2cb",
        "papermill": {
          "duration": 0.147534,
          "end_time": "2024-04-20T04:52:12.146158",
          "exception": false,
          "start_time": "2024-04-20T04:52:11.998624",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Install requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "7720d692",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7720d692",
        "outputId": "9d76b59f-81d3-46d6-daaa-19cb406ca09e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Notebook cleaned.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import IPython\n",
        "import sys\n",
        "\n",
        "def clean_notebook():\n",
        "    IPython.display.clear_output(wait=True)\n",
        "    print(\"Notebook cleaned.\")\n",
        "\n",
        "# Installs Unsloth, Xformers (Flash Attention) and all other packages!\n",
        "\n",
        "!pip install datasets peft accelerate bitsandbytes\n",
        "\n",
        "# Clean up the notebook\n",
        "clean_notebook()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21e6d936",
      "metadata": {
        "id": "21e6d936",
        "papermill": {
          "duration": 0.145914,
          "end_time": "2024-04-20T04:54:27.251167",
          "exception": false,
          "start_time": "2024-04-20T04:54:27.105253",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Set up environment variables\n",
        "\n",
        "This is set with kaggle secret collection. If you're runing with other enviroment, they can be set .env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "aaf0d781",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-20T04:54:27.549815Z",
          "iopub.status.busy": "2024-04-20T04:54:27.549468Z",
          "iopub.status.idle": "2024-04-20T04:54:27.953378Z",
          "shell.execute_reply": "2024-04-20T04:54:27.952586Z"
        },
        "id": "aaf0d781",
        "papermill": {
          "duration": 0.555595,
          "end_time": "2024-04-20T04:54:27.955815",
          "exception": false,
          "start_time": "2024-04-20T04:54:27.400220",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['HF_TOKEN']         =\"code\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91b7293f",
      "metadata": {
        "id": "91b7293f",
        "papermill": {
          "duration": 0.146046,
          "end_time": "2024-04-20T04:54:28.249126",
          "exception": false,
          "start_time": "2024-04-20T04:54:28.103080",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Select dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "31c74ef9",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-20T04:54:28.549807Z",
          "iopub.status.busy": "2024-04-20T04:54:28.549463Z",
          "iopub.status.idle": "2024-04-20T04:54:28.553847Z",
          "shell.execute_reply": "2024-04-20T04:54:28.552937Z"
        },
        "id": "31c74ef9",
        "papermill": {
          "duration": 0.155525,
          "end_time": "2024-04-20T04:54:28.555905",
          "exception": false,
          "start_time": "2024-04-20T04:54:28.400380",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "dataset_id = \"Thaweewat/thai-med-pack\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c2ccb8d",
      "metadata": {
        "id": "3c2ccb8d",
        "papermill": {
          "duration": 0.147398,
          "end_time": "2024-04-20T04:54:28.849712",
          "exception": false,
          "start_time": "2024-04-20T04:54:28.702314",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Load tokenizer and model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a80d66d5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190,
          "referenced_widgets": [
            "7d245d13cec14fffbeabfdc6896b1dbf",
            "988ae91c763347c69b434d515b8a9f7e",
            "e3d6721a2af64f74a0aa9a9219352172",
            "14964aba0eca453b8bc95e00b80a8734",
            "06e5d937d1284c32a57ba82e66259d24",
            "63f8796692f7497d94227a9171fc9c27",
            "7d88052277a84fbc9193236321a72b8a",
            "ac877611509348f19b4ee27bbc2bf91e",
            "5b347a348b464123a5f52319aecbbebb",
            "0be9b6592f2e41c380a81cb14ef51f20",
            "59eea92369c74b00a8e6e7c7e621ad93"
          ]
        },
        "execution": {
          "iopub.execute_input": "2024-04-20T04:54:29.147136Z",
          "iopub.status.busy": "2024-04-20T04:54:29.146325Z",
          "iopub.status.idle": "2024-04-20T04:55:53.612048Z",
          "shell.execute_reply": "2024-04-20T04:55:53.611225Z"
        },
        "id": "a80d66d5",
        "outputId": "3626ce0c-f7ae-4a81-ba8f-350663dd66d6",
        "papermill": {
          "duration": 84.613319,
          "end_time": "2024-04-20T04:55:53.614426",
          "exception": false,
          "start_time": "2024-04-20T04:54:29.001107",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "326a76f1fc384c8b8e9c658a51bf2573",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "\n",
        "\n",
        "model_id = \"scb10x/llama-3-typhoon-v1.5-8b\"\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map=\"auto\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b57dd36e",
      "metadata": {
        "id": "b57dd36e",
        "papermill": {
          "duration": 0.147415,
          "end_time": "2024-04-20T04:55:53.911491",
          "exception": false,
          "start_time": "2024-04-20T04:55:53.764076",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "Then we have to apply some preprocessing to the model to prepare it for training. For that use the `prepare_model_for_kbit_training` method from PEFT."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8228170",
      "metadata": {
        "id": "a8228170",
        "papermill": {
          "duration": 0.146126,
          "end_time": "2024-04-20T04:55:54.203547",
          "exception": false,
          "start_time": "2024-04-20T04:55:54.057421",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Set up trainable parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "01bc977b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-20T04:55:54.498222Z",
          "iopub.status.busy": "2024-04-20T04:55:54.497381Z",
          "iopub.status.idle": "2024-04-20T04:55:55.607447Z",
          "shell.execute_reply": "2024-04-20T04:55:55.606644Z"
        },
        "id": "01bc977b",
        "papermill": {
          "duration": 1.259278,
          "end_time": "2024-04-20T04:55:55.609727",
          "exception": false,
          "start_time": "2024-04-20T04:55:54.350449",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "from peft import prepare_model_for_kbit_training\n",
        "\n",
        "model.gradient_checkpointing_enable()\n",
        "model = prepare_model_for_kbit_training(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "334e3b14",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-20T04:55:55.936393Z",
          "iopub.status.busy": "2024-04-20T04:55:55.935479Z",
          "iopub.status.idle": "2024-04-20T04:55:55.941813Z",
          "shell.execute_reply": "2024-04-20T04:55:55.940865Z"
        },
        "id": "334e3b14",
        "papermill": {
          "duration": 0.179484,
          "end_time": "2024-04-20T04:55:55.944006",
          "exception": false,
          "start_time": "2024-04-20T04:55:55.764522",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "def print_trainable_parameters(model):\n",
        "    \"\"\"\n",
        "    Prints the number of trainable parameters in the model.\n",
        "    \"\"\"\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_param += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "    print(\n",
        "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "cea8bf43",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-04-20T04:55:56.264531Z",
          "iopub.status.busy": "2024-04-20T04:55:56.263638Z",
          "iopub.status.idle": "2024-04-20T04:55:56.271999Z",
          "shell.execute_reply": "2024-04-20T04:55:56.271056Z"
        },
        "id": "cea8bf43",
        "outputId": "4c10f41b-dd87-49d4-c8cd-ada9e90e627c",
        "papermill": {
          "duration": 0.170612,
          "end_time": "2024-04-20T04:55:56.274308",
          "exception": false,
          "start_time": "2024-04-20T04:55:56.103696",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LlamaForCausalLM(\n",
            "  (model): LlamaModel(\n",
            "    (embed_tokens): Embedding(128256, 4096)\n",
            "    (layers): ModuleList(\n",
            "      (0-31): 32 x LlamaDecoderLayer(\n",
            "        (self_attn): LlamaSdpaAttention(\n",
            "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
            "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
            "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
            "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
            "          (rotary_emb): LlamaRotaryEmbedding()\n",
            "        )\n",
            "        (mlp): LlamaMLP(\n",
            "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
            "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
            "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
            "          (act_fn): SiLU()\n",
            "        )\n",
            "        (input_layernorm): LlamaRMSNorm()\n",
            "        (post_attention_layernorm): LlamaRMSNorm()\n",
            "      )\n",
            "    )\n",
            "    (norm): LlamaRMSNorm()\n",
            "  )\n",
            "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "09253f0e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-04-20T04:55:56.579672Z",
          "iopub.status.busy": "2024-04-20T04:55:56.578837Z",
          "iopub.status.idle": "2024-04-20T04:56:01.126483Z",
          "shell.execute_reply": "2024-04-20T04:56:01.125328Z"
        },
        "id": "09253f0e",
        "outputId": "05d5e741-0de9-49a7-9239-223d551c149a",
        "papermill": {
          "duration": 4.702485,
          "end_time": "2024-04-20T04:56:01.128989",
          "exception": false,
          "start_time": "2024-04-20T04:55:56.426504",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 52428800 || all params: 4593029120 || trainable%: 1.141486340064833\n"
          ]
        }
      ],
      "source": [
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "config = LoraConfig(\n",
        "    r=20,\n",
        "    lora_alpha=32,\n",
        "    target_modules=\"all-linear\",\n",
        "#     target_modules=[\"lm_head\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, config)\n",
        "print_trainable_parameters(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfd3bd4d",
      "metadata": {
        "id": "dfd3bd4d",
        "papermill": {
          "duration": 0.149958,
          "end_time": "2024-04-20T04:56:01.430032",
          "exception": false,
          "start_time": "2024-04-20T04:56:01.280074",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Preprocess dataset\n",
        "\n",
        "I parsed into `# Instruction: # Input: # Response:` also I added `<answer></answer>` xml and response but you may modify it. I just like this way :D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "ea9a05e6",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-20T04:56:01.736850Z",
          "iopub.status.busy": "2024-04-20T04:56:01.736444Z",
          "iopub.status.idle": "2024-04-20T04:58:05.336735Z",
          "shell.execute_reply": "2024-04-20T04:58:05.335720Z"
        },
        "id": "ea9a05e6",
        "papermill": {
          "duration": 123.758599,
          "end_time": "2024-04-20T04:58:05.339372",
          "exception": false,
          "start_time": "2024-04-20T04:56:01.580773",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "from datasets import load_dataset\n",
        "\n",
        "data = load_dataset(dataset_id)\n",
        "\n",
        "\n",
        "def parse(text: str) -> str:\n",
        "    try:\n",
        "        question_search = re.search(r'\\[INST\\](.*)\\[/INST\\]', text, re.IGNORECASE)\n",
        "        question = question_search.group(1).strip()\n",
        "\n",
        "\n",
        "        answer_search = re.search(r'\\[/INST\\](.*)\\</s\\>', text, re.IGNORECASE)\n",
        "        answer = answer_search.group(1).strip()\n",
        "        spec = f\"\"\"<s>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
        "### Instruction:\n",
        "Act as a doctor and response the input question from a patient in Thai language with XML format <answer>Your answer</answer>\n",
        "### Input:\n",
        "{question}\n",
        "### Response:\n",
        "<answer> {answer} </answer>\n",
        "</s>\"\"\"\n",
        "    except:\n",
        "        print(text)\n",
        "        raise\n",
        "    return {\n",
        "        \"spec\": spec\n",
        "    }\n",
        "\n",
        "\n",
        "# parse(data[\"train\"][\"text\"][0])\n",
        "# data.map(lambda )\n",
        "data = data.map(lambda samples: parse(samples[\"text\"]), batch_size=8,num_proc=os.cpu_count())\n",
        "data = data.map(lambda samples: tokenizer(samples[\"spec\"]), batched=True, batch_size=8,num_proc=os.cpu_count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LMOy3m9iKGIt",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMOy3m9iKGIt",
        "outputId": "748b5592-755e-4b3e-bb63-7b1bc1a0e15a"
      },
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bpghMyNXKVP1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 775
        },
        "id": "bpghMyNXKVP1",
        "outputId": "eb95eacd-615e-4e3d-b65a-76dc11b6d9d0"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Markdown, display\n",
        "\n",
        "\n",
        "idx = 5\n",
        "\n",
        "display(Markdown(f\"**text:**\\n\\n{data['train'][idx]['text']}\"))\n",
        "display(Markdown(\"---\"))\n",
        "display(Markdown(f\"**spec:**\\n\\n{data['train'][idx]['spec']}\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d9c9c1e",
      "metadata": {
        "id": "2d9c9c1e",
        "papermill": {
          "duration": 0.148907,
          "end_time": "2024-04-20T04:58:05.639191",
          "exception": false,
          "start_time": "2024-04-20T04:58:05.490284",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed63e1cd",
      "metadata": {
        "id": "ed63e1cd",
        "papermill": {
          "duration": 0.151999,
          "end_time": "2024-04-20T04:58:05.945375",
          "exception": false,
          "start_time": "2024-04-20T04:58:05.793376",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83901364",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "execution": {
          "iopub.execute_input": "2024-04-20T04:58:06.248805Z",
          "iopub.status.busy": "2024-04-20T04:58:06.248435Z",
          "iopub.status.idle": "2024-04-20T08:58:01.706047Z",
          "shell.execute_reply": "2024-04-20T08:58:01.705072Z"
        },
        "id": "83901364",
        "outputId": "414d5aac-4024-4ea5-e927-eb2e8d97ef85",
        "papermill": {
          "duration": 14395.760286,
          "end_time": "2024-04-20T08:58:01.858572",
          "exception": false,
          "start_time": "2024-04-20T04:58:06.098286",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
        "\n",
        "# Clear the GPU cache\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Set the padding token for the tokenizer\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Define the data collator\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
        "\n",
        "# Set up the training arguments\n",
        "training_args = TrainingArguments(\n",
        "    per_device_train_batch_size=15,  # Adjusted batch size\n",
        "    gradient_accumulation_steps=4,  # Adjust gradient accumulation steps\n",
        "    max_steps=35,\n",
        "    learning_rate=1e-5,\n",
        "    logging_steps=1,\n",
        "    output_dir=\"outputs\",\n",
        "    #optim=\"paged_adamw_8bit\",\n",
        "    load_best_model_at_end=True,\n",
        "    save_strategy=\"no\"\n",
        "    \n",
        ")\n",
        "\n",
        "# Define the trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    train_dataset=data[\"train\"],\n",
        "    args=training_args,\n",
        "    data_collator=data_collator\n",
        "\n",
        ")\n",
        "\n",
        "# # Disable caching to silence warnings (enable for inference)\n",
        "model.config.use_cache = False\n",
        "\n",
        "# # Enable gradient checkpointing for memory efficiency\n",
        "model.gradient_checkpointing_enable()\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c596c956",
      "metadata": {
        "id": "c596c956",
        "papermill": {
          "duration": 0.159903,
          "end_time": "2024-04-20T08:58:02.176515",
          "exception": false,
          "start_time": "2024-04-20T08:58:02.016612",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Export model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e10ab8eb",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-20T08:58:02.495664Z",
          "iopub.status.busy": "2024-04-20T08:58:02.494042Z",
          "iopub.status.idle": "2024-04-20T08:58:04.522921Z",
          "shell.execute_reply": "2024-04-20T08:58:04.521783Z"
        },
        "id": "e10ab8eb",
        "papermill": {
          "duration": 2.190565,
          "end_time": "2024-04-20T08:58:04.525395",
          "exception": false,
          "start_time": "2024-04-20T08:58:02.334830",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "model_to_save = trainer.model.module if hasattr(trainer.model, 'module') else trainer.model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(\"outputs\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18d72b99",
      "metadata": {
        "id": "18d72b99",
        "papermill": {
          "duration": 0.210631,
          "end_time": "2024-04-20T08:58:04.952003",
          "exception": false,
          "start_time": "2024-04-20T08:58:04.741372",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Test model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb6ab22b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-20T08:58:05.355010Z",
          "iopub.status.busy": "2024-04-20T08:58:05.354061Z",
          "iopub.status.idle": "2024-04-20T09:06:40.677057Z",
          "shell.execute_reply": "2024-04-20T09:06:40.676153Z"
        },
        "id": "fb6ab22b",
        "papermill": {
          "duration": 515.657837,
          "end_time": "2024-04-20T09:06:40.836233",
          "exception": false,
          "start_time": "2024-04-20T08:58:05.178396",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "from transformers import  StoppingCriteria, StoppingCriteriaList\n",
        "\n",
        "class KeywordsStoppingCriteria(StoppingCriteria):\n",
        "    def __init__(self, keywords_ids:list):\n",
        "        self._i = 0\n",
        "        self.keywords = keywords_ids\n",
        "\n",
        "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
        "        text = tokenizer.decode(\n",
        "                input_ids[0],\n",
        "                skip_special_tokens=True\n",
        "        )\n",
        "        if text.strip().endswith(\"</answer>\"):\n",
        "            return True\n",
        "        if self._i % 50 == 0:\n",
        "            print(text)\n",
        "            print(\"-\" * 16)\n",
        "        self._i += 1\n",
        "        if input_ids[0][-1] in self.keywords:\n",
        "\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "stop_words = ['</answer>']\n",
        "\n",
        "\n",
        "stop_ids = [tokenizer.encode(w) for w in stop_words]\n",
        "stop_criteria = KeywordsStoppingCriteria(stop_ids)\n",
        "\n",
        "stopping_criteria = StoppingCriteriaList([stop_criteria])\n",
        "\n",
        "\n",
        "text = \"\"\"<s>Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
        "### Instruction:\n",
        "Act as a doctor and response the input question from a patient in Thai language with XML format <answer>Your answer</answer>\n",
        "### Input:\n",
        "คือผมอยากทราบว่า อาการที่ผมเป็นตอนนี้คือกรดไหลย้อน หรือ เป็นสัญญาณของพิษสุนัขบ้าครับ ผมมีอาการ เเน่นๆ อึดอัดที่คอ เเล้วก็ กลืนน้ำลายลำบากครับ ก่อนหน้านี้มีไข้ต่ำ ปวดหัวนิดหน่อยครับ ช่วง 1 เดือนก่อน ผมทำงานเดินทางโดยจักรยานครับ ทางผ่านมีสุนัขอยู่ตามทางเยอะมากๆ (เเต่จากที่เห็นไม่ได้เห่าเเละไล่ตามผมครับ) เเล้วมาพึ่งมาเป็นอาการดังกล่าวช่วงนี้ครับ ผมจึงไม่เเน่ใจว่าเป็นกรดไหลย้อนหรือเป็นสัญญานอาการเเรกเริ่มของพิษสุนัขบ้าหรอครับ ผมอ่านเเล้วเห็นอาการคล้ายๆกันครับคุณ รบกวนด้วยนะครับ\n",
        "### Response:\"\"\"\n",
        "\n",
        "device = \"cuda:0\"\n",
        "\n",
        "lora_config = LoraConfig.from_pretrained('outputs')\n",
        "model = get_peft_model(model, lora_config)\n",
        "\n",
        "inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
        "outputs = model_to_save.generate(\n",
        "    **inputs, max_new_tokens=400,\n",
        "    stopping_criteria=stopping_criteria,\n",
        "    pad_token_id=tokenizer.eos_token_id,\n",
        "    no_repeat_ngram_size=10,\n",
        "    forced_eos_token_id=tokenizer.eos_token_id,\n",
        "    do_sample=True,\n",
        "    top_p=0.95\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "display(tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c555090",
      "metadata": {},
      "outputs": [],
      "source": [
        "display(tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92524db2",
      "metadata": {
        "id": "92524db2",
        "papermill": {
          "duration": 0.158763,
          "end_time": "2024-04-20T09:06:41.154360",
          "exception": false,
          "start_time": "2024-04-20T09:06:40.995597",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# (Optional) Push trained model to your Huggingface account"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "121a192f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-20T09:06:41.470406Z",
          "iopub.status.busy": "2024-04-20T09:06:41.469557Z",
          "iopub.status.idle": "2024-04-20T09:07:21.043389Z",
          "shell.execute_reply": "2024-04-20T09:07:21.042341Z"
        },
        "id": "121a192f",
        "papermill": {
          "duration": 39.733143,
          "end_time": "2024-04-20T09:07:21.045473",
          "exception": false,
          "start_time": "2024-04-20T09:06:41.312330",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "model_to_save.push_to_hub(\"typhoon-med\")\n",
        "tokenizer.push_to_hub(\"typhoon-med\")\n",
        "model_to_save.config.push_to_hub(\"typhoon-med\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30683,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 15394.457684,
      "end_time": "2024-04-20T09:08:43.283811",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2024-04-20T04:52:08.826127",
      "version": "2.5.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "06e5d937d1284c32a57ba82e66259d24": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0be9b6592f2e41c380a81cb14ef51f20": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14964aba0eca453b8bc95e00b80a8734": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0be9b6592f2e41c380a81cb14ef51f20",
            "placeholder": "​",
            "style": "IPY_MODEL_59eea92369c74b00a8e6e7c7e621ad93",
            "value": " 4/4 [00:10&lt;00:00,  2.32s/it]"
          }
        },
        "59eea92369c74b00a8e6e7c7e621ad93": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b347a348b464123a5f52319aecbbebb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "63f8796692f7497d94227a9171fc9c27": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d245d13cec14fffbeabfdc6896b1dbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_988ae91c763347c69b434d515b8a9f7e",
              "IPY_MODEL_e3d6721a2af64f74a0aa9a9219352172",
              "IPY_MODEL_14964aba0eca453b8bc95e00b80a8734"
            ],
            "layout": "IPY_MODEL_06e5d937d1284c32a57ba82e66259d24"
          }
        },
        "7d88052277a84fbc9193236321a72b8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "988ae91c763347c69b434d515b8a9f7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63f8796692f7497d94227a9171fc9c27",
            "placeholder": "​",
            "style": "IPY_MODEL_7d88052277a84fbc9193236321a72b8a",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "ac877611509348f19b4ee27bbc2bf91e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3d6721a2af64f74a0aa9a9219352172": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac877611509348f19b4ee27bbc2bf91e",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5b347a348b464123a5f52319aecbbebb",
            "value": 4
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
