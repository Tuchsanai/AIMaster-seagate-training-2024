{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "87737056",
      "metadata": {},
      "source": [
        "Why?\n",
        "\n",
        "* Want to estimate costs (pay per token)\n",
        "* Want to ensure your prompt doesn't exceed max sequence length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a4d173e6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Notebook cleaned.\n"
          ]
        }
      ],
      "source": [
        "import IPython\n",
        "import sys\n",
        "\n",
        "def clean_notebook():\n",
        "    IPython.display.clear_output(wait=True)\n",
        "    print(\"Notebook cleaned.\")\n",
        "\n",
        "!pip install openai\n",
        "!pip install gradio\n",
        "!pip install tiktoken\n",
        "\n",
        "# Clean up the notebook\n",
        "clean_notebook()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFJd4PmsxjKb"
      },
      "source": [
        "![](https://deeplearningcourses.com/notebooks_v3_pxl?sc=AVRK7SgM9ASkQf5TAqs_wA&n=Tiktoken)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "1f1637e8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoded tokens 9: [36748, 38313, 24152, 36748, 38133, 29419, 41427, 23084, 84646]\n"
          ]
        }
      ],
      "source": [
        "import tiktoken\n",
        "\n",
        "# Get the encoding for the model\n",
        "encoding = tiktoken.encoding_for_model('gpt-3.5-turbo')\n",
        "\n",
        "# Thai text to encode\n",
        "thai_text = \"สวัสดีครับ\"\n",
        "\n",
        "# Encode the Thai text\n",
        "tokens = encoding.encode(thai_text)\n",
        "print(f\"Encoded tokens {len(tokens)}:\", tokens)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "f610ba71",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Token: 36748, ส\n",
            "Token: 38313, ว\n",
            "Token: 24152, ั\n",
            "Token: 36748, ส\n",
            "Token: 38133, ด\n",
            "Token: 29419, ี\n",
            "Token: 41427, ค\n",
            "Token: 23084, ร\n",
            "Token: 84646, ับ\n"
          ]
        }
      ],
      "source": [
        "for token in tokens:\n",
        "    print(f\"Token: {token}, {encoding.decode([token])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "61621869",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Decoded text: สวัสดีครับ\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Decode the tokens back to Thai text\n",
        "decoded_text = encoding.decode(tokens)\n",
        "print(\"Decoded text:\", decoded_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ea0e15b",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "sc": "AVRK7SgM9ASkQf5TAqs_wA"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
